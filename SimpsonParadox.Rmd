---
title: "Simpson Paradox Illustrated"
author: "Christophe Bontemps (UN SIAP)^[ Based on the work by Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton (Modern Data Science with R - 2023)]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: no
    keep_md: no
    code_folding: hide
    code_download: true
    highlight: tango
    number_sections: no
    theme: cerulean
  pdf_document:
    keep_tex: yes
  word_document: default
---

`r if(knitr:::pandoc_to() == "latex") {paste("\\large")}` 

```{r setup, include=FALSE}
# Remember to disable png for Word export...
knitr::opts_chunk$set( message = FALSE, warning = FALSE, 
                       results = TRUE, echo = TRUE,
                       fig.width=7, fig.height=4, 
                       dev="png", 
                       dev.args=list(type="cairo"), dpi=96)

# My colors:
SIAP.color <- "#0385a8"

# Function used to recreate ggplot standard colors
ggplotColours <- function(n = 6, h = c(0, 360) + 15){
  if ((diff(h) %% 360) < 1) h[2] <- h[2] - 360/n
  hcl(h = (seq(h[1], h[2], length = n)), c = 100, l = 65)
}

```


```{r packages, include=FALSE, echo = FALSE}
# Data management packages
library(jtools)
library(forcats)
library(tidyverse)

# Plotting packages
library(ggplot2)
library(RColorBrewer)
library(plotly)


# Nice presentation of results
library(papeR)
library(xtable)
library(kableExtra)

# Tables 
library(modelsummary)
library(gt) 
library(gtsummary)
library(skimr)

```

## A classical analysis

Let’s use real data (2010) and analyze the relation between the average teacher salaries and the  average total SAT scores for each of the 50 United States. The SAT (*Scholastic Aptitude Test*) is a high-stakes exam used for entry into college in the US. The data were collected by Baumer *et al.* (2021) and available on their [Github page](https://github.com/mdsr-book/mdsr/tree/master/data). 

> Are higher teacher salaries associated with better outcomes on the SAT test? 

If so, should we adjust salaries to improve test performance? 

Let's look at the relation between SAT's scores (Y) and  Teachers Slaries (X). We can do a simple scatterplot of these data. We also fit a linear regression model.


```{r}
# From https://mdsr-book.github.io/mdsr3e/09-foundations.html#sec-confound
 load(file = 'data/SAT_2010.rda')


SAT_2010 <- SAT_2010 |>
  mutate(Salary = salary/1000)

SAT_plot <- ggplot(data = SAT_2010, aes(x = Salary, y = total)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  ylab("Average total score on the SAT") + 
  xlab("Average teacher salary (thousands of USD)") +
  theme_minimal()
SAT_plot
```

The regression associated  shows that the coeficient is clearly **negative** and significantly different from 0. 

```{r}
SAT_mod1 <- lm(total ~ Salary, data = SAT_2010)
broom::tidy(SAT_mod1)
```
> Are higher teacher less paid in states where the STA is higher?  Or...

###  Is there a factor not taken into account in this analysis? 

Looking at the data, we may find interesting that there is quite a discrepancy in the *Average percentage of students who take the SAT in each state*, as the histogram of the variable *sat_pct* shows clearly. 

```{r}
SAT_2010 %>%
  ggplot() + 
  aes(x=sat_pct) +
  geom_histogram(fill=SIAP.color) + 

  xlab("Average percentage of students who take the SAT in each state ") +
  theme_minimal()


```

Let us create a dummy variable to differentiate the two groups of states according to the participation rate in SAT.  The median participation rate  is at  **`r median(SAT_2010$sat_pct)`**, but th histogram shows a clear-cut separation anywhere between 30% and 45%. So let's split the sample into two groups: *high* and *low* rates of participation and capture this information in the variable *sat_grp*. 

```{r}
# New variable created sat_grp

SAT_2010 <- SAT_2010 |>
  mutate(sat_grp = ifelse(sat_pct < 30, "Low", "High"))

SAT_2010 |>
  group_by(sat_grp) |>
  count()
```

```{r}
SAT_2010 %>%
  ggplot() + 
  aes(x=sat_pct, fill = sat_grp) +
  geom_histogram( ) + 
  scale_fill_manual(values = c("pink", SIAP.color)) +
  xlab("Average percentage of students who take the SAT in each state ") +
  theme_minimal()


```




##  Taking the rate of participation into account. 

There are various ways to take into account the presence of two groups. Let's simply visualize the effect by adjusting a regression line for each the two groups.  

```{r}
SAT_plot %+% SAT_2010 + 
  aes(color = sat_grp) + 
  scale_fill_manual(values = c("pink", SIAP.color)) 

# scale_color_brewer("% taking\nthe SAT", palette = "Set1")

```

> **Within** each  groups, average teacher salary is **positively** associated with average SAT score! 


Let us look at the linear regressions for each group independently.  


```{r}
SAT_2010 |>
  group_by(sat_grp) |>
  group_modify(~broom::tidy(lm(total ~ Salary, data = .x)))
```


One now understands the previous analysis, where both highly participating states were analysed together with states experiencing a lower rate of participation. 

This paradox -  with a relation that change sign depending on how we treat the data and whether or not one has included an additional explanatory variable - is called **Simpson’s paradox**.  

If we compute the linear regression taking into account the high and low rates of SAT participation - *as we should have done* - one can confirm the positive association between average teachers salary and average SAT scores:

```{r}
SAT_mod2 <- lm(total ~ Salary + sat_pct, data = SAT_2010)
broom::tidy(SAT_mod2)
```

> The Simpson paradox  is very common and results from a bad understanding of the data set and the omission of important explanatory factors. 

### Morality

Be careful in your analysis and ask yourself: 

- What is the expected sign of a relation? (before plotting/computing)
- Which variables play or could play a role in the analysis?
- Is there something wrong in what I am doing/viewing?

The Simpson paradox has been documented in various publications and in [Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox)

<img src="assets/Simpsons.png" alt="Simpson's" />


```{r EXIT, echo=FALSE}
knitr::knit_exit()
```









```{r}
# Generating data with Simpson's paradox
set.seed(2512)

# Creating a dataset with three variables: X, Y, and Group
n <- 300
x <- rnorm(n, mean = 20, sd = 5)
y <- 3 * x + rnorm(n, mean = 0, sd = 10)
group <- factor(rep(1:3, each = n/3))

# Introducing Simpson's paradox
grouped_x <- split(x, group)
grouped_y <- split(y, group)

# Increasing the correlation within each subgroup
grouped_y[[1]] <- grouped_y[[1]] - 3 * grouped_x[[1]]* rnorm(n/3, mean = 1, sd = 3)
grouped_y[[2]] <- grouped_y[[2]] + 3 * grouped_x[[2]]* rnorm(n/3, mean = 1.2, sd = 3)
grouped_y[[3]] <- grouped_y[[3]] - 3 * grouped_x[[3]]* rnorm(n/3, mean = 1.5, sd = 3)

# Removing one data point from each group to have consistent number of rows
grouped_x <- lapply(grouped_x, function(x) x[-sample(length(x), 1)])
grouped_y <- lapply(grouped_y, function(y) y[-sample(length(y), 1)])

x <- unlist(grouped_x)
y <- unlist(grouped_y)

# Creating the final dataset
data <- data.frame(X = x, Y = y, Group = group[1:297])

```

# Stat des
```{r}
# Visualization of the paradox with regression lines and small multiples
# Plot with regression lines
ggplot(data, aes(x = X, y = Y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox",
       x = "X", y = "Y")
```


```{r}
# Visualization of the paradox with regression lines and small multiples
# Plot with regression lines
ggplot(data, aes(x = X, y = Y, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox",
       x = "X", y = "Y")
```

```{r}
# Plot with small multiples
ggplot(data, aes(x = X, y = Y, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~Group) +
  labs(title = "Simpson's Paradox: Small Multiples",
       x = "X", y = "Y")

```


```{r}
# Generating data with Simpson's paradox in another way
set.seed(42)

# Creating a dataset with three variables: University, Applicants, and Admitted
university <- c(rep("University A", 100), rep("University B", 200))
applicants <- c(500, 200, 400, 100, 200, 150)
admitted <- c(250, 180, 350, 90, 100, 120)

# Creating the final dataset
data_another <- data.frame(University = university, Applicants = applicants, Admitted = admitted)

```


```{r}
# Calculate admission rates for each university
data_another$Admission_Rate <- data_another$Admitted / data_another$Applicants * 100
data_another

```

```{r}
# Adding gender information to the dataset
gender <- c(rep("Male", 200), rep("Female", 100))
data_another$Gender <- gender

# Calculate admission rates for each university and gender
admission_rates_by_gender <- aggregate(Admitted ~ University + Gender, data_another, sum)
applicants_by_gender <- aggregate(Applicants ~ University + Gender, data_another, sum)
data_another_gender <- merge(admission_rates_by_gender, applicants_by_gender, by = c("University", "Gender"))

data_another_gender$Admission_Rate_Gender <- data_another_gender$Admitted / data_another_gender$Applicants * 100
data_another_gender

```

## 2 

```{r}
# Generating data with Simpson's paradox in another way
set.seed(42)

# Creating a dataset with three variables: University, Applicants, and Admitted
university <- c(rep("University A", 100), rep("University B", 200))
applicants <- c(500, 200, 400, 100, 200, 150)
admitted <- c(250, 180, 350, 90, 100, 120)

# Creating the final dataset
data_another <- data.frame(University = university, Applicants = applicants, Admitted = admitted)

```



```{r}
# Visualization of the paradox with regression lines
ggplot(data_another, aes(x = Applicants, y = Admission_Rate, color = University)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox: Admission Rates by University",
       x = "Number of Applicants", y = "Admission Rate (%)") +
  theme_minimal()

```






####  New

```{r}
# Generating data with Simpson's paradox
set.seed(42)

# Creating a dataset with three variables: X, Y, and Group
n <- 100
x <- c(rnorm(n, mean = 10, sd = 2), rnorm(n, mean = 30, sd = 5))
y <- c(2 * x[1:n] + rnorm(n, mean = 0, sd = 2), 3 * x[(n+1):(2*n)] + rnorm(n, mean = 0, sd = 5))
group <- factor(rep(1:2, each = n))

# Creating the final dataset
data_simpson <- data.frame(X = x, Y = y, Group = group)

```

```{r}
# Visualization of the paradox with regression lines
ggplot(data_simpson, aes(x = X, y = Y, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox: X vs. Y",
       x = "X", y = "Y") +
  theme_minimal()

```

```{r}
# Visualization of the combined data with regression line
ggplot(data_simpson, aes(x = X, y = Y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox: Combined Data",
       x = "X", y = "Y") +
  theme_minimal()

```

```{r}
# Generating data with Simpson's paradox
set.seed(42)

# Creating a dataset with three variables: X, Y, and Group
n <- 100
x <- c(rnorm(n, mean = 10, sd = 2), rnorm(n, mean = 30, sd = 5))
y <- c(2 * x[1:n] + rnorm(n, mean = 0, sd = 2), 3 * x[(n+1):(2*n)] + rnorm(n, mean = 0, sd = 5))
group <- factor(rep(1:2, each = n))

# Creating the final dataset
data_simpson <- data.frame(X = x, Y = y, Group = group)

```


```{r}
# Visualization of the paradox with regression lines
ggplot(data_simpson, aes(x = X, y = Y, color = Group)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Simpson's Paradox: X vs. Y",
       x = "X", y = "Y") +
  theme_minimal()

```

